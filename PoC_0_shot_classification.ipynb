{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "IS-ZfwyIVM0K",
        "-T53nEheWGBb",
        "J4vT8Ci-YaIB",
        "wLLab46aXdT3",
        "QkMYkwiqCfm0",
        "X3QHTo0xius7",
        "FXQzYZOJGj1y"
      ],
      "authorship_tag": "ABX9TyOSDVjbjGRSAW27ItRoZiax",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/delemarchand2020/TestsAzureAI/blob/main/PoC_0_shot_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Classification avec AzureVision OCR + Embedding Azure AI (OpenAI) + Cos-similarité"
      ],
      "metadata": {
        "id": "ruEs4TP4VVJK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Installation des librairies"
      ],
      "metadata": {
        "id": "IS-ZfwyIVM0K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBFSnNQ3VC2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab228d77-acfd-4fed-9381-4965ddebb2ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m497.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.3/194.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q azure-ai-vision-imageanalysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "kWhksfhTVhpR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5442447c-0e72-417f-a3fb-75474395bdff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.1/318.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pdf2image"
      ],
      "metadata": {
        "id": "j74wbwgeCz0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install poppler-utils"
      ],
      "metadata": {
        "id": "jvpk2OjUEvdi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4326d975-db14-4af0-a592-1cd89a439dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.4 [186 kB]\n",
            "Fetched 186 kB in 1s (250 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 121913 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.4) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.4) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q docx2pdf"
      ],
      "metadata": {
        "id": "pW95DGTaG5Se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai num2words matplotlib plotly scipy scikit-learn pandas tiktoken"
      ],
      "metadata": {
        "id": "SYyDVSrKekOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dec043da-39bb-44d8-d6e6-4903a7840630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/325.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/325.5 kB\u001b[0m \u001b[31m839.9 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/325.5 kB\u001b[0m \u001b[31m895.6 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.8/325.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K60oHPACMEUn",
        "outputId": "e9a646f3-ed1e-44a7-cc56-973903de41bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Chargement des clés Azure et OpenAI"
      ],
      "metadata": {
        "id": "-T53nEheWGBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VISION_ENDPOINT = \"https://demo-desj-azure-ai.cognitiveservices.azure.com/\""
      ],
      "metadata": {
        "id": "YFTSE7XuWvIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chemin du fichier après le montage de Google Drive\n",
        "file_path = \"/content/gdrive/MyDrive/key.openai.txt\"\n",
        "\n",
        "# Lire le contenu du fichier\n",
        "with open(file_path, 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Configuration initiale de l'API OpenAI\n",
        "openai_api_key = content"
      ],
      "metadata": {
        "id": "EsJbzweyLqHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chemin du fichier après le montage de Google Drive\n",
        "file_path = \"/content/gdrive/MyDrive/key.azure.txt\"\n",
        "\n",
        "# Lire le contenu du fichier\n",
        "with open(file_path, 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Configuration initiale de l'API Azure\n",
        "VISION_KEY = content"
      ],
      "metadata": {
        "id": "8M4TpXN1O-78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Chargement d'images de test"
      ],
      "metadata": {
        "id": "J4vT8Ci-YaIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! ls -l \"/content/gdrive/MyDrive/recu_masso_photo.jpg\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYnpDVENYgH-",
        "outputId": "fbd7cee8-ef8a-4d9f-fcac-42237c98d8ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 676809 Apr 21 21:12 /content/gdrive/MyDrive/recu_masso_photo.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/gdrive/MyDrive/recu_masso_photo.jpg\" .\n",
        "!cp \"/content/gdrive/MyDrive/McGill_Enrolment_Letter_2023-2024.pdf\" .\n",
        "!cp \"/content/gdrive/MyDrive/releve_notes.pdf\" .\n",
        "!cp \"/content/gdrive/MyDrive/billet_medecin.jpg\" .\n",
        "!cp \"/content/gdrive/MyDrive/fac_ortho.jpg\" ."
      ],
      "metadata": {
        "id": "JZ00OVbwYqnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fonctions utiles"
      ],
      "metadata": {
        "id": "mv6gBjyOXco_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Conversion PDF ou DOCX en image"
      ],
      "metadata": {
        "id": "wLLab46aXdT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "import os\n",
        "\n",
        "def convert_pdf_to_jpg(file_path):\n",
        "    # Vérifier si le fichier existe\n",
        "    if not os.path.isfile(file_path):\n",
        "        raise FileNotFoundError(\"Le fichier spécifié n'existe pas.\")\n",
        "\n",
        "    # Vérifier si le fichier est un fichier PDF\n",
        "    if not file_path.lower().endswith('.pdf'):\n",
        "        return file_path\n",
        "\n",
        "    # Chemin du fichier JPEG de sortie\n",
        "    jpg_path = os.path.splitext(file_path)[0] + \".jpg\"\n",
        "\n",
        "    # Convertir le PDF en une liste d'images PIL\n",
        "    images = convert_from_path(file_path)\n",
        "\n",
        "    # Sauvegarder la première image en tant que fichier JPEG\n",
        "    images[0].save(jpg_path, \"JPEG\")\n",
        "\n",
        "    # Retourner le chemin du fichier JPEG\n",
        "    return jpg_path"
      ],
      "metadata": {
        "id": "T2pZejvGCqTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from docx2pdf import convert\n",
        "\n",
        "def convert_docx_to_pdf(file_path):\n",
        "    # Vérifier si le fichier existe\n",
        "    if not os.path.isfile(file_path):\n",
        "        raise FileNotFoundError(\"Le fichier spécifié n'existe pas.\")\n",
        "\n",
        "    # Vérifier si le fichier est un fichier DOCX\n",
        "    if not file_path.lower().endswith('.docx'):\n",
        "        return file_path\n",
        "\n",
        "    # Chemin du fichier PDF de sortie\n",
        "    pdf_path = os.path.splitext(file_path)[0] + \".pdf\"\n",
        "\n",
        "    # Convertir le fichier DOCX en PDF\n",
        "    convert(file_path, pdf_path)\n",
        "\n",
        "    # Retourner le chemin du fichier PDF\n",
        "    return convert_pdf_to_jpg(pdf_path)\n"
      ],
      "metadata": {
        "id": "Xm3P4udJGmtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "def get_PIL_image(img_path):\n",
        "  with open(img_path, 'rb') as image_file:\n",
        "      content = image_file.read()\n",
        "  return Image.open(io.BytesIO(content))"
      ],
      "metadata": {
        "id": "xPgE6VUCMnRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def convert_cos_sim_to_angle(cos_sim):\n",
        "    # Calcul de l'angle en radians\n",
        "    angle_rad = np.arccos(cos_sim)\n",
        "\n",
        "    # Conversion de radians en degrés\n",
        "    angle_deg = np.degrees(angle_rad)\n",
        "\n",
        "    return round(angle_deg,1)"
      ],
      "metadata": {
        "id": "tkqwqsMaKsYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Pre-traitement textes"
      ],
      "metadata": {
        "id": "QkMYkwiqCfm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Définir les expressions régulières pour les dates, les prix, les mots français (y compris les accents) et les nombres\n",
        "date_regex = re.compile(r'\\b\\d{1,2}/\\d{1,2}/\\d{2,4}\\b|\\b\\d{1,2}-\\d{1,2}-\\d{2,4}\\b|\\b\\d{4}-\\d{2}-\\d{2}\\b|\\b\\d{2,4}/\\d{2}/\\d{2,4}\\b')\n",
        "price_regex = re.compile(r'\\b\\d+[\\.,]?\\d*\\s?(€|EUR|euros?|dollars?|USD|CHF)\\b')\n",
        "french_word_regex = re.compile(r'\\b[a-zA-ZàâäéèêëîïôöùûüÿçÀÂÄÉÈÊËÎÏÔÖÙÛÜŸÇ]+\\b')\n",
        "number_regex = re.compile(r'\\b\\d+\\b')\n",
        "\n",
        "# Définir une expression régulière pour les éléments indésirables (ponctuation et autres caractères non désirés)\n",
        "unwanted_regex = re.compile(r'[^\\w\\s€|EUR|euros|dollars|USD|CHFàâäéèêëîïôöùûüÿçÀÂÄÉÈÊËÎÏÔÖÙÛÜŸÇ\\'/-]')\n",
        "\n",
        "# Fonction pour filtrer le texte\n",
        "def filter_text(text):\n",
        "    filtered_elements = []\n",
        "    words = text.split()\n",
        "\n",
        "    for word in words:\n",
        "        # Supprimer les signes de ponctuation et autres caractères non désirés\n",
        "        clean_word = unwanted_regex.sub('', word)\n",
        "\n",
        "        if date_regex.match(clean_word) or price_regex.match(clean_word) or french_word_regex.match(clean_word) or number_regex.match(clean_word):\n",
        "            filtered_elements.append(clean_word)\n",
        "\n",
        "    return ' '.join(filtered_elements)"
      ],
      "metadata": {
        "id": "zW2Hg2sjCs61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Test pré-traitement\n",
        "# Exemple d'utilisation\n",
        "text = \"Bonjour, je veux acheter une voiture le 12/06/2024 pour 1500 EUR. Mon chat aime bien jouer avec la souris. La date d'aujourd'hui est 2024-06-10. J'ai 2 chats et 1 chien.\"\n",
        "filtered_text = filter_text(text)\n",
        "print(filtered_text)"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7l2jja9MXuS",
        "outputId": "1d666bda-1373-4067-80ae-4afe90cefe7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bonjour je veux acheter une voiture le 12/06/2024 pour 1500 EUR Mon chat aime bien jouer avec la souris La date d'aujourd'hui est 2024-06-10 J'ai 2 chats et 1 chien\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Appels Azure Vision\n",
        "https://learn.microsoft.com/fr-ca/python/api/overview/azure/ai-vision-imageanalysis-readme?view=azure-python-preview"
      ],
      "metadata": {
        "id": "0BQUwvcHXm8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
        "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "\n",
        "# Set the values of your computer vision endpoint and computer vision key\n",
        "# as environment variables:\n",
        "try:\n",
        "    endpoint = VISION_ENDPOINT\n",
        "    key = VISION_KEY\n",
        "except KeyError:\n",
        "    print(\"Missing environment variable 'VISION_ENDPOINT' or 'VISION_KEY'\")\n",
        "    print(\"Set them before running this sample.\")\n",
        "    exit()\n",
        "\n",
        "# Create an Image Analysis client for synchronous operations\n",
        "client = ImageAnalysisClient(\n",
        "    endpoint=endpoint,\n",
        "    credential=AzureKeyCredential(key)\n",
        ")"
      ],
      "metadata": {
        "id": "mdBVcijLXg7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Test AzureVision\n",
        "test=True\n",
        "\n",
        "if test:\n",
        "    # Load image to analyze into a 'bytes' object\n",
        "    with open(\"billet_medecin.jpg\", \"rb\") as f:\n",
        "        image_data = f.read()\n",
        "\n",
        "    # Extract text (OCR) from an image stream. This will be a synchronously (blocking) call.\n",
        "    result = client.analyze(\n",
        "        image_data=image_data,\n",
        "        visual_features=[VisualFeatures.READ, VisualFeatures.OBJECTS, VisualFeatures.TAGS]\n",
        "    )\n",
        "\n",
        "    # Print text (OCR) analysis results to the console\n",
        "    #print(\"Image analysis results:\")\n",
        "    #print(\" Read:\")\n",
        "    #if result.read is not None:\n",
        "    #  if result.read.blocks != []:\n",
        "    #    for line in result.read.blocks[0].lines:\n",
        "    #        print(f\"   Line: '{line.text}', Bounding box {line.bounding_polygon}\")\n",
        "    #        for word in line.words:\n",
        "    #            print(f\"     Word: '{word.text}', Bounding polygon {word.bounding_polygon}, Confidence {word.confidence:.4f}\")\n",
        "    if result.tags is not None:\n",
        "      print(\" Tags:\")\n",
        "      for o in result.tags.list:\n",
        "          print(f\"   tag: '{o}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cVSkc4-cX5g",
        "outputId": "493142f1-d343-4637-b028-ae3e16bd6749",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Tags:\n",
            "   tag: '{'name': 'text', 'confidence': 0.9999884366989136}'\n",
            "   tag: '{'name': 'handwriting', 'confidence': 0.9781054258346558}'\n",
            "   tag: '{'name': 'ink', 'confidence': 0.9036840200424194}'\n",
            "   tag: '{'name': 'paper', 'confidence': 0.9036159515380859}'\n",
            "   tag: '{'name': 'letter', 'confidence': 0.8745496869087219}'\n",
            "   tag: '{'name': 'paper product', 'confidence': 0.8620651960372925}'\n",
            "   tag: '{'name': 'calligraphy', 'confidence': 0.8448852300643921}'\n",
            "   tag: '{'name': 'document', 'confidence': 0.5845139026641846}'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get text (OCR) analysis results\n",
        "def get_all_words(result):\n",
        "    all_words = []\n",
        "    if result.read.blocks != []:\n",
        "      for line in result.read.blocks[0].lines:\n",
        "          for word in line.words:\n",
        "              all_words.append(word.text)\n",
        "    return all_words\n",
        "\n",
        "def get_all_tags(result):\n",
        "    all_tags = []\n",
        "    if result.tags is not None:\n",
        "      all_tags = result.tags.list\n",
        "    return all_tags\n",
        "\n",
        "if test:\n",
        "  print(get_all_words(result))\n",
        "  print(get_all_tags(result))"
      ],
      "metadata": {
        "id": "EnXYFpLWc7xJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13d67e9e-e5c9-4a15-f503-70cb93fc0141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['HYGEA', 'clinique', 'médicale', '5100', 'boul.', 'de', 'Maisonneuve', 'O.', 'Bureau', '710', 'Tél.', ':', '514-938-0995', 'Montréal', '(Qc)', 'H4A', '3T2', 'Fax', ':', '514-938-4476', 'Date:', 'Sul', '31123', 'Marina', 'Grandin', 'Nom', ':', 'Addresse', ':', 'R', 'Custom', 'orthotics', 'Dx', 'Hallux', 'Valgus', 'Geld', 'sman', '87582']\n",
            "[{'name': 'text', 'confidence': 0.9999884366989136}, {'name': 'handwriting', 'confidence': 0.9781054258346558}, {'name': 'ink', 'confidence': 0.9036840200424194}, {'name': 'paper', 'confidence': 0.9036159515380859}, {'name': 'letter', 'confidence': 0.8745496869087219}, {'name': 'paper product', 'confidence': 0.8620651960372925}, {'name': 'calligraphy', 'confidence': 0.8448852300643921}, {'name': 'document', 'confidence': 0.5845139026641846}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty dictionary to store the extracted text\n",
        "text_dict = {}\n",
        "tags_dict = {}\n",
        "\n",
        "def document_texts_detection(img_path, debug=False):\n",
        "    # Check if the image has already been seen\n",
        "    if img_path not in text_dict:\n",
        "        # Load image to analyze into a 'bytes' object\n",
        "        with open(img_path, \"rb\") as f:\n",
        "            image_data = f.read()\n",
        "\n",
        "        # Extract text (OCR) from an image stream. This will be a synchronously (blocking) call.\n",
        "        result = client.analyze(\n",
        "            image_data=image_data,\n",
        "            visual_features=[VisualFeatures.READ, VisualFeatures.TAGS]\n",
        "        )\n",
        "        # Store the extracted text in the dictionary\n",
        "        text_dict[img_path] = get_all_words(result)\n",
        "        tags_dict[img_path] = get_all_tags(result)\n",
        "\n",
        "    # Return the extracted text from the dictionary\n",
        "    return text_dict[img_path], tags_dict[img_path]\n"
      ],
      "metadata": {
        "id": "TQyQ0-cUMQTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Appels OpenAI pour embeddings\n",
        "https://learn.microsoft.com/en-us/azure/ai-services/openai/tutorials/embeddings?tabs=python-new%2Ccommand-line&pivots=programming-language-python"
      ],
      "metadata": {
        "id": "nRloA_YvXvS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import openai\n",
        "\n",
        "openai.api_key = openai_api_key\n",
        "\n",
        "client_openai = OpenAI(api_key=openai.api_key)"
      ],
      "metadata": {
        "id": "B0ESjaQLoFuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Initialize an empty dictionary to store the embeddings\n",
        "embeddings_dict = {}\n",
        "\n",
        "def get_text_embedding(input, model=\"text-embedding-3-small\"):\n",
        "\n",
        "    if input != None and input != \"\":\n",
        "        # Check if the input has already been seen\n",
        "        if input not in embeddings_dict:\n",
        "            embeddings_batch_response_openAI = client_openai.embeddings.create(input = [input], model=model)\n",
        "            # Store the embedding in the dictionary\n",
        "            embeddings_dict[input] = np.array([embeddings_batch_response_openAI.data[0].embedding])\n",
        "        # Return the embedding from the dictionary\n",
        "        return embeddings_dict[input]\n",
        "    else:\n",
        "        return np.zeros((1, 1536))"
      ],
      "metadata": {
        "id": "cu7S2WEyHcou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tests des appels"
      ],
      "metadata": {
        "id": "X3QHTo0xius7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = document_texts_detection(img_path=\"recu_masso_photo.jpg\", debug=False)"
      ],
      "metadata": {
        "id": "c97yS-pGizik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Nombre de mots/token détectés: {len(texts)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMh0FP2yjjRA",
        "outputId": "a4435997-a0da-426e-8874-9d41cd5af817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre de mots/token détectés: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Texte pour test\n",
        "texte = \"\"\"\n",
        "Université\n",
        "de Montréal\n",
        "Denis Lemarchand\n",
        "4958 avenue grosvenor\n",
        "montreal QC H3W 2M1\n",
        "Canada\n",
        "Programme d'études:\n",
        "Spécialisation:\n",
        "Relevé de notes non officiel\n",
        "Relevé des études de cycles supérieurs\n",
        "Automne 2022\n",
        "217510 Informatique (Maîtrise)\n",
        "Apprentissage automatique (Spécialisation)\n",
        "Date d'émission:\n",
        "Matricule:\n",
        "CPER QC:\n",
        "2024-01-25\n",
        "20241211\n",
        "LEMD02036912\n",
        "Cours\n",
        "IFT 6390\n",
        "Description\n",
        "Crédits:\n",
        "Apprent. machine: fondements\n",
        "Suivis\n",
        "4.000\n",
        "Obtenus\n",
        "4.000\n",
        "Note Points\n",
        "A\n",
        "16.000\n",
        "Moy.gr.\n",
        "2-175-1-0 72 Cours à option\n",
        "Crédits:\n",
        "Suivis\n",
        "Moyenne générale trimestrielle\n",
        "4.000 Total du trimestre\n",
        "4.000\n",
        "Obtenus\n",
        "4.000\n",
        "Moy.\n",
        "4.000\n",
        "Points\n",
        "16.000\n",
        "Hiver 2023\n",
        "Programme d'études:\n",
        "Spécialisation:\n",
        "217510 Informatique (Maîtrise)\n",
        "Apprentissage automatique (Spécialisation)\n",
        "Cours\n",
        "Description\n",
        "Crédits:\n",
        "IFT 6135\n",
        "Aprentissage de représent.\n",
        "Suivis\n",
        "4.000\n",
        "Obtenus\n",
        "4.000\n",
        "Note Points\n",
        "A-\n",
        "14.800\n",
        "Moy.gr.\n",
        "2-175-1-0 72 Cours à option\n",
        "Crédits:\n",
        "Moyenne générale trimestrielle\n",
        "3.700 Total du trimestre\n",
        "Suivis\n",
        "4.000\n",
        "Obtenus\n",
        "4.000\n",
        "Moy.\n",
        "4.000\n",
        "Points\n",
        "14.800\n",
        "Automne 2023\n",
        "Programme d'études:\n",
        "Spécialisation:\n",
        "217510 Informatique (Maîtrise)\n",
        "Apprentissage automatique (Spécialisation)\n",
        "Cours\n",
        "Description\n",
        "Crédits:\n",
        "IFT 6758\n",
        "Science des données\n",
        "Suivis\n",
        "4.000\n",
        "Obtenus\n",
        "4.000\n",
        "Note Points\n",
        "A\n",
        "16.000\n",
        "Moy.gr.\n",
        "2-175-1-0 72 Cours à option\n",
        "Crédits:\n",
        "Suivis\n",
        "Moyenne générale trimestrielle\n",
        "4.000 Total du trimestre\n",
        "4.000\n",
        "Obtenus\n",
        "4.000\n",
        "Moy.\n",
        "4.000\n",
        "Points\n",
        "16.000\n",
        "Hiver 2024\n",
        "Programme d'études:\n",
        "Spécialisation:\n",
        "217510 Informatique (Maîtrise)\n",
        "Intelligence artificielle (Spécialisation)\n",
        "Cours\n",
        "Description\n",
        "Crédits:\n",
        "IFT 6261\n",
        "Traitement des connaissances\n",
        "2-175-1-0 72 Cours à option\n",
        "Suivis\n",
        "Obtenus Note\n",
        "Points\n",
        "Moy.gr.\n",
        "Pour être officiel, le relevé de notes doit porter le sceau de l'Université et la signature du Registraire.\n",
        "Page 1 de 2\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "pvBn5arra0QD",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tests similarité"
      ],
      "metadata": {
        "id": "FXQzYZOJGj1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texte1 = \"j'aime les pommes, en dessert\"\n",
        "texte2 = \"as-tu vu le gratte-ciel\"\n",
        "vector1 = get_text_embedding(texte1)\n",
        "vector2 = get_text_embedding(texte2)\n",
        "cosine_similarity(vector1, vector2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfSDYrFPGqXV",
        "outputId": "6c2924fd-8a9b-44b5-a9e2-eb81039cdf86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.25363956]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_cosine_similarity(vector1, vector2):\n",
        "    #Produit scalaire des vecteurs\n",
        "    scalar_product = np.dot(vector1, vector2.T)\n",
        "    #Norme euclidienne des vecteurs\n",
        "    norm_vector1 = np.linalg.norm(vector1)\n",
        "    norm_vector2 = np.linalg.norm(vector2)\n",
        "    #Expression analytique du cosinus dans un espace euclidien\n",
        "    cosine = scalar_product / (norm_vector1 * norm_vector2)\n",
        "    return cosine\n",
        "\n",
        "my_cosine_similarity(vector1, vector2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeeVZX37Bw0J",
        "outputId": "3d0faa94-603a-4550-af55-c724efc5d637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.25363956]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#text-embedding-ada-002, text-embedding-3-small, text-embedding-3-large\n",
        "model=\"text-embedding-3-large\"\n",
        "cosine_similarity(get_text_embedding(texte1, model=model), get_text_embedding(texte2, model=model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYncEhYyKNDU",
        "outputId": "0a0bed1f-362b-4a15-fb55-5a2c4a93c6ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.25363956]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Classification"
      ],
      "metadata": {
        "id": "AkTfVi4OC4vW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the mapping of sub-types to types\n",
        "type_mapping = {\n",
        "    \"Relevé de notes officiel universitaire\": \"Preuve de scolarité\",\n",
        "    \"Relevé de notes non officiel universitaire\": \"Preuve de scolarité\",\n",
        "    \"Facture session universitaire\": \"Preuve de scolarité\",\n",
        "    \"Horaire de cours\": \"Preuve de scolarité\",\n",
        "    \"Bulletin cumulatif de notes\": \"Preuve de scolarité\",\n",
        "\n",
        "    \"Certificat médical\": \"Billet du médecin\",\n",
        "    \"Formulaire d'arrêt de travail\": \"Billet du médecin\",\n",
        "    \"Billet du medecin\": \"Billet du médecin\",\n",
        "    \"Prescription médicale\": \"Billet du médecin\",\n",
        "    \"Ordonnance médicale clinique\": \"Billet du médecin\",\n",
        "\n",
        "    \"Spécimen de chèque\": \"Spécimen de chèque\",\n",
        "    \"Payer à l'ordre de\": \"Spécimen de chèque\",\n",
        "    \"100 dollars\": \"Spécimen de chèque\",\n",
        "    \"Banque\": \"Spécimen de chèque\",\n",
        "    \"MICR code\": \"Spécimen de chèque\",\n",
        "\n",
        "    \"Facture soins dentaires\": \"Facture\",\n",
        "    \"Facture soin thérapeutique\": \"Facture\",\n",
        "    \"Facture ou reçu soin massage thérapeutique\": \"Facture\",\n",
        "    \"Facture et services\": \"Facture\"\n",
        "}\n",
        "\n",
        "# Derive types_doc from type_mapping\n",
        "sous_types_doc = list(type_mapping.keys())\n",
        "sous_types_doc_original = sous_types_doc.copy()\n",
        "type_mapping_original = type_mapping.copy()"
      ],
      "metadata": {
        "id": "x31_1u0HJlUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def classify_text(texte, sous_types_doc, seuil=0.4):\n",
        "    classification = {}\n",
        "    insert_autre = False\n",
        "    total_score = 0\n",
        "\n",
        "    # Calcul de la similarité pour chaque type de document\n",
        "    for sous_type in sous_types_doc:\n",
        "        similarity_score = cosine_similarity(get_text_embedding(texte), get_text_embedding(sous_type))[0][0]\n",
        "        if similarity_score >= seuil:\n",
        "            doc_type = type_mapping[sous_type]\n",
        "            if doc_type in classification:\n",
        "                classification[doc_type][\"cumul des scores de similarité\"] += similarity_score\n",
        "            else:\n",
        "                classification[doc_type] = {\"cumul des scores de similarité\": similarity_score}\n",
        "            total_score += similarity_score\n",
        "        elif not insert_autre:\n",
        "            if \"Autre\" in classification:\n",
        "                classification[\"Autre\"][\"cumul des scores de similarité\"] += seuil\n",
        "            else:\n",
        "                classification[\"Autre\"] = {\"cumul des scores de similarité\": seuil}\n",
        "            total_score += seuil\n",
        "            insert_autre = True\n",
        "\n",
        "    # Calcul du pourcentage de chaque score de similarité\n",
        "    for doc_type, item in classification.items():\n",
        "        item[\"part dans la classification (%)\"] = round((item[\"cumul des scores de similarité\"] / total_score) * 100, 2)\n",
        "\n",
        "    # Tri des résultats par score de similarité en ordre décroissant\n",
        "    sorted_classification = sorted(classification.items(), key=lambda x: x[1][\"cumul des scores de similarité\"], reverse=True)\n",
        "\n",
        "    # Conversion de la liste triée en format JSON\n",
        "    return json.dumps(sorted_classification, indent=4)"
      ],
      "metadata": {
        "id": "Yfm4kyoxJ2Vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Test classification\n",
        "classification_sorted = classify_text(filter_text(texte), sous_types_doc, seuil=0.45)\n",
        "print(classification_sorted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ9Fj4i4rQj4",
        "outputId": "cd8734c9-f93c-4a09-bd04-58dbef0cd1fc",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    [\n",
            "        \"Preuve de scolarit\\u00e9\",\n",
            "        {\n",
            "            \"cumul des scores de similarit\\u00e9\": 1.6311968816563556,\n",
            "            \"part dans la classification (%)\": 78.38\n",
            "        }\n",
            "    ],\n",
            "    [\n",
            "        \"Autre\",\n",
            "        {\n",
            "            \"cumul des scores de similarit\\u00e9\": 0.45,\n",
            "            \"part dans la classification (%)\": 21.62\n",
            "        }\n",
            "    ]\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Interface UI pour la démo"
      ],
      "metadata": {
        "id": "stynIthZjKca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_document(img_path, new_type_doc, categorie, parametres, seuil):\n",
        "    global sous_types_doc_original, type_mapping_original, sous_types_doc, type_mapping\n",
        "\n",
        "    img_path = convert_pdf_to_jpg(img_path)\n",
        "    img_path = convert_docx_to_pdf(img_path)\n",
        "    texts, tags = document_texts_detection(img_path=img_path)\n",
        "    texts = \" \".join(texts)\n",
        "    image = get_PIL_image(img_path=img_path)\n",
        "\n",
        "    if \"Réinitialiser la liste des sous-types/types\" in parametres:\n",
        "        types_doc_etendu = sous_types_doc_original.copy()\n",
        "        sous_types_doc = sous_types_doc_original.copy()\n",
        "        type_mapping = type_mapping_original.copy()\n",
        "    else:\n",
        "        types_doc_etendu = sous_types_doc.copy()\n",
        "        if new_type_doc != \"\":\n",
        "            if new_type_doc not in sous_types_doc:\n",
        "                types_doc_etendu.append(new_type_doc)\n",
        "                # Add the new type to the type_mapping dictionary\n",
        "                type_mapping[new_type_doc] = categorie\n",
        "\n",
        "    if \"Nettoyage Texte\" in parametres:\n",
        "        texts = filter_text(texts)\n",
        "\n",
        "    analyse = classify_text(texts, types_doc_etendu, seuil=seuil)\n",
        "\n",
        "    return image, analyse, texts, tags, type_mapping"
      ],
      "metadata": {
        "id": "Z8JJU2p7KTTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# URL de l'image du diagramme\n",
        "#diagram_url = \"https://diagrams.helpful.dev/d/d:P8TaRIVr-png-base-64-for-mobile\"\n",
        "diagram_url = \"https://mermaid.ink/img/pako:eNp9U0FOwzAQ_MrKF0CiPCCHSqj0gIRUiSJOuSz2ElZK7GBvKgriQX1HP8Y6TUtpgFxie2cmuzPxh7HBkSlMoteOvKUbxipiU3rQp8UobLlFL3ATbNeQLjDB7AVjRf3OdeCGyphz22BFPSH4FcXEwQN54Hw8Ri9m9xk7f5OIVjJWxYXehOD8-r2LBI-cJS7G1HnzRM6xr3qB1KIlWJGVKzhftOSvb78Rv7BnIbGnJTdcY2RZ7zpuFIKctA1dQNpXt5u_vXlYt5Qy-46Tdu3OthsfvN1uEjgC0Wp-7_1KY6F7Sl0tRxISebuhcQc76v67k-m0t7oYkolQ00ksfV1xanIxxCEcT9LQokIOVhW7LFid38VAAqXJvobIiWJpfrbRj_9ToDSPR3A49iNlQ0IdKqbBiQNPNU4zKYZEdLZshg1pMorklDNRncHRApahH7hGqP911lyahmKD7PRWfGTh0siL_uylyeM4ekYVzKN_KhQ7Ccu1t6aQ2NGl6VqHsr9EpnjGOh1O547VieHw8wur_0EX?type=png\"\n",
        "cosin_similarity_graph = \"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dyH20eCqb6qTL-gt4nCVzQ.png\"\n",
        "\n",
        "# Interface Gradio\n",
        "demo = gr.Blocks()\n",
        "\n",
        "with demo:\n",
        "    gr.Markdown(\"# Démo IDP - OCR (ici Azure Vision) - Classification par similarité\")\n",
        "    gr.Image(value=diagram_url, label=\"\")\n",
        "\n",
        "    gr.Interface(\n",
        "            fn=process_document,\n",
        "            inputs=[gr.File(label=\"Fichier\", type=\"filepath\", file_types=[\".jpg\",\".pdf\",\".png\",\".docx\"]),\n",
        "                    gr.Textbox(label=\"Ajouter un sous-type de document\"),\n",
        "                    gr.Dropdown(\n",
        "                        [\"Preuve de scolarité\", \"Billet du médecin\", \"Spécimen de chèque\", \"Facture\"], label=\"Dans la catégorie\", value=\"Preuve de scolarité\"),\n",
        "                    gr.CheckboxGroup([\"Nettoyage du texte\", \"Réinitialiser la liste des sous-types/types\"], label=\"Paramètres\"),\n",
        "                    gr.Slider(0.0, 1, value=0.4, label=\"Seuil\")],\n",
        "            outputs=[gr.Image(label=\"Image du doc\", type=\"pil\"), #gr.Textbox(label=\"Langue détectée\"),\n",
        "                     gr.Json(label=\"Classification par similarité (0-Shot classification)\"),\n",
        "                     gr.Textbox(label=\"Tous les mots extraits (et filtrés)\"),\n",
        "                     gr.Json(label=\"Tags extraits\"),\n",
        "                     gr.Json(label=\"Regroupement des sous-types par types (actuellement en mémoire)\")],\n",
        "            title=None,\n",
        "            examples= [[\"fac_ortho.jpg\"],[\"billet_medecin.jpg\"],[\"recu_masso_photo.jpg\"],[\"McGill_Enrolment_Letter_2023-2024.pdf\"],[\"releve_notes.pdf\"]],\n",
        "            cache_examples=False, allow_flagging='never', clear_btn=None)\n",
        "\n",
        "    gr.Image(value=cosin_similarity_graph, label=\"\")"
      ],
      "metadata": {
        "id": "s54GdWR3jQcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "kJpgmOyiksgo",
        "outputId": "cd143101-14fa-4a7a-8883-d21ee0fdf849"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://9f2d28eec1e365f46f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://9f2d28eec1e365f46f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://9f2d28eec1e365f46f.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}