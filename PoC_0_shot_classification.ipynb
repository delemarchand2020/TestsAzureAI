{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "IS-ZfwyIVM0K",
        "-T53nEheWGBb",
        "J4vT8Ci-YaIB",
        "wLLab46aXdT3",
        "QkMYkwiqCfm0",
        "X3QHTo0xius7"
      ],
      "authorship_tag": "ABX9TyMk4HeJudE1ltmqh9/FHKcN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/delemarchand2020/TestsAzureAI/blob/main/PoC_0_shot_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Classification avec AzureVision OCR + Embedding Azure AI (OpenAI) + Cos-similarité\n",
        "https://medium.com/@jh.baek.sd/concised-vector-embeddings-for-beginners-guide-3907793e7b10\n",
        "\n",
        "Autre solution mais impliquant des LLM et voici pourquoi:\n",
        "* https://levelup.gitconnected.com/advanced-document-classification-with-llms-8801eaee3c58\n"
      ],
      "metadata": {
        "id": "ruEs4TP4VVJK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Installation des librairies"
      ],
      "metadata": {
        "id": "IS-ZfwyIVM0K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PBFSnNQ3VC2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6817ebd5-ff5b-4e14-b12e-2f30be7c0166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.3/194.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q azure-ai-vision-imageanalysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "kWhksfhTVhpR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aa8716f-5515-4bd4-95d8-b58444795261"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.2/318.2 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pdf2image"
      ],
      "metadata": {
        "id": "j74wbwgeCz0U"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install poppler-utils"
      ],
      "metadata": {
        "id": "jvpk2OjUEvdi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53de075b-989e-4363-8e0a-8a29d8876cf5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.4 [186 kB]\n",
            "Fetched 186 kB in 1s (125 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 121925 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.4) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.4) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q docx2pdf"
      ],
      "metadata": {
        "id": "pW95DGTaG5Se"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai num2words matplotlib plotly scipy scikit-learn pandas tiktoken"
      ],
      "metadata": {
        "id": "SYyDVSrKekOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d88adae1-f5e9-48df-d90c-f1f1c644c5fc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/328.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.4/328.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m327.7/328.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.3/328.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Chargement des clés Azure et OpenAI"
      ],
      "metadata": {
        "id": "-T53nEheWGBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VISION_ENDPOINT = \"https://demo-desj-azure-ai.cognitiveservices.azure.com/\""
      ],
      "metadata": {
        "id": "YFTSE7XuWvIT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cljp5xtdO1-7",
        "outputId": "b62efe50-dca6-4452-82a0-6c77122b2ea4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chemin du fichier après le montage de Google Drive\n",
        "file_path = \"/content/gdrive/MyDrive/key.openai.txt\"\n",
        "\n",
        "# Lire le contenu du fichier\n",
        "with open(file_path, 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Configuration initiale de l'API OpenAI\n",
        "openai_api_key = content"
      ],
      "metadata": {
        "id": "EsJbzweyLqHR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chemin du fichier après le montage de Google Drive\n",
        "file_path = \"/content/gdrive/MyDrive/key.azure.txt\"\n",
        "\n",
        "# Lire le contenu du fichier\n",
        "with open(file_path, 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Configuration initiale de l'API Azure\n",
        "VISION_KEY = content"
      ],
      "metadata": {
        "id": "8M4TpXN1O-78"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Chargement d'images de test"
      ],
      "metadata": {
        "id": "J4vT8Ci-YaIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/delemarchand2020/ExtractDataFromImageDoc/raw/main/recu_masso_photo.png -O recu_masso_photo.png\n",
        "!wget https://github.com/delemarchand2020/ExtractDataFromImageDoc/raw/main/billet_medecin.png -O billet_medecin.png\n",
        "!wget https://github.com/delemarchand2020/ExtractDataFromImageDoc/raw/main/fac_ortho.jpg -O fac_ortho.jpg\n",
        "!wget https://github.com/delemarchand2020/ExtractDataFromImageDoc/raw/main/releve_notes.pdf -O releve_notes.pdf\n",
        "!wget https://github.com/delemarchand2020/ExtractDataFromImageDoc/raw/main/McGill_Enrolment_Letter_2023-2024.pdf -O McGill_Enrolment_Letter_2023-2024.pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06mLBLwOM8OE",
        "outputId": "8b6b07c0-d865-44e7-a101-8104d250d8b0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-08 10:37:42--  https://github.com/delemarchand2020/ExtractDataFromImageDoc/raw/main/recu_masso_photo.png\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/delemarchand2020/ExtractDataFromImageDoc/main/recu_masso_photo.png [following]\n",
            "--2024-07-08 10:37:43--  https://raw.githubusercontent.com/delemarchand2020/ExtractDataFromImageDoc/main/recu_masso_photo.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3541129 (3.4M) [image/png]\n",
            "Saving to: ‘recu_masso_photo.png’\n",
            "\n",
            "recu_masso_photo.pn 100%[===================>]   3.38M  12.7MB/s    in 0.3s    \n",
            "\n",
            "2024-07-08 10:37:44 (12.7 MB/s) - ‘recu_masso_photo.png’ saved [3541129/3541129]\n",
            "\n",
            "--2024-07-08 10:37:44--  https://github.com/delemarchand2020/ExtractDataFromImageDoc/raw/main/billet_medecin.png\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/delemarchand2020/ExtractDataFromImageDoc/main/billet_medecin.png [following]\n",
            "--2024-07-08 10:37:45--  https://raw.githubusercontent.com/delemarchand2020/ExtractDataFromImageDoc/main/billet_medecin.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8827101 (8.4M) [application/octet-stream]\n",
            "Saving to: ‘billet_medecin.png’\n",
            "\n",
            "billet_medecin.png  100%[===================>]   8.42M  27.3MB/s    in 0.3s    \n",
            "\n",
            "2024-07-08 10:37:46 (27.3 MB/s) - ‘billet_medecin.png’ saved [8827101/8827101]\n",
            "\n",
            "--2024-07-08 10:37:46--  https://github.com/delemarchand2020/ExtractDataFromImageDoc/raw/main/fac_ortho.jpg\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/delemarchand2020/ExtractDataFromImageDoc/main/fac_ortho.jpg [following]\n",
            "--2024-07-08 10:37:47--  https://raw.githubusercontent.com/delemarchand2020/ExtractDataFromImageDoc/main/fac_ortho.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 601616 (588K) [image/jpeg]\n",
            "Saving to: ‘fac_ortho.jpg’\n",
            "\n",
            "fac_ortho.jpg       100%[===================>] 587.52K  3.31MB/s    in 0.2s    \n",
            "\n",
            "2024-07-08 10:37:48 (3.31 MB/s) - ‘fac_ortho.jpg’ saved [601616/601616]\n",
            "\n",
            "--2024-07-08 10:37:48--  https://github.com/delemarchand2020/ExtractDataFromImageDoc/raw/main/releve_notes.pdf\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/delemarchand2020/ExtractDataFromImageDoc/main/releve_notes.pdf [following]\n",
            "--2024-07-08 10:37:48--  https://raw.githubusercontent.com/delemarchand2020/ExtractDataFromImageDoc/main/releve_notes.pdf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23511 (23K) [application/octet-stream]\n",
            "Saving to: ‘releve_notes.pdf’\n",
            "\n",
            "releve_notes.pdf    100%[===================>]  22.96K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-07-08 10:37:49 (4.00 MB/s) - ‘releve_notes.pdf’ saved [23511/23511]\n",
            "\n",
            "--2024-07-08 10:37:49--  https://github.com/delemarchand2020/ExtractDataFromImageDoc/raw/main/McGill_Enrolment_Letter_2023-2024.pdf\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/delemarchand2020/ExtractDataFromImageDoc/main/McGill_Enrolment_Letter_2023-2024.pdf [following]\n",
            "--2024-07-08 10:37:49--  https://raw.githubusercontent.com/delemarchand2020/ExtractDataFromImageDoc/main/McGill_Enrolment_Letter_2023-2024.pdf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 154612 (151K) [application/octet-stream]\n",
            "Saving to: ‘McGill_Enrolment_Letter_2023-2024.pdf’\n",
            "\n",
            "McGill_Enrolment_Le 100%[===================>] 150.99K  --.-KB/s    in 0.09s   \n",
            "\n",
            "2024-07-08 10:37:50 (1.64 MB/s) - ‘McGill_Enrolment_Letter_2023-2024.pdf’ saved [154612/154612]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fonctions utiles"
      ],
      "metadata": {
        "id": "mv6gBjyOXco_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Conversion PDF ou DOCX en image"
      ],
      "metadata": {
        "id": "wLLab46aXdT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "import os\n",
        "\n",
        "def convert_pdf_to_jpg(file_path):\n",
        "    # Vérifier si le fichier existe\n",
        "    if not os.path.isfile(file_path):\n",
        "        raise FileNotFoundError(\"Le fichier spécifié n'existe pas.\")\n",
        "\n",
        "    # Vérifier si le fichier est un fichier PDF\n",
        "    if not file_path.lower().endswith('.pdf'):\n",
        "        return file_path\n",
        "\n",
        "    # Chemin du fichier JPEG de sortie\n",
        "    jpg_path = os.path.splitext(file_path)[0] + \".jpg\"\n",
        "\n",
        "    # Convertir le PDF en une liste d'images PIL\n",
        "    images = convert_from_path(file_path)\n",
        "\n",
        "    # Sauvegarder la première image en tant que fichier JPEG\n",
        "    images[0].save(jpg_path, \"JPEG\")\n",
        "\n",
        "    # Retourner le chemin du fichier JPEG\n",
        "    return jpg_path"
      ],
      "metadata": {
        "id": "T2pZejvGCqTV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from docx2pdf import convert\n",
        "\n",
        "def convert_docx_to_pdf(file_path):\n",
        "    # Vérifier si le fichier existe\n",
        "    if not os.path.isfile(file_path):\n",
        "        raise FileNotFoundError(\"Le fichier spécifié n'existe pas.\")\n",
        "\n",
        "    # Vérifier si le fichier est un fichier DOCX\n",
        "    if not file_path.lower().endswith('.docx'):\n",
        "        return file_path\n",
        "\n",
        "    # Chemin du fichier PDF de sortie\n",
        "    pdf_path = os.path.splitext(file_path)[0] + \".pdf\"\n",
        "\n",
        "    # Convertir le fichier DOCX en PDF\n",
        "    convert(file_path, pdf_path)\n",
        "\n",
        "    # Retourner le chemin du fichier PDF\n",
        "    return convert_pdf_to_jpg(pdf_path)\n"
      ],
      "metadata": {
        "id": "Xm3P4udJGmtc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "def get_PIL_image(img_path):\n",
        "  with open(img_path, 'rb') as image_file:\n",
        "      content = image_file.read()\n",
        "  return Image.open(io.BytesIO(content))"
      ],
      "metadata": {
        "id": "xPgE6VUCMnRk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def convert_cos_sim_to_angle(cos_sim):\n",
        "    # Calcul de l'angle en radians\n",
        "    angle_rad = np.arccos(cos_sim)\n",
        "\n",
        "    # Conversion de radians en degrés\n",
        "    angle_deg = np.degrees(angle_rad)\n",
        "\n",
        "    return round(angle_deg,1)"
      ],
      "metadata": {
        "id": "tkqwqsMaKsYs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Pre-traitement textes"
      ],
      "metadata": {
        "id": "QkMYkwiqCfm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Définir les expressions régulières pour les dates, les prix, les mots français (y compris les accents) et les nombres\n",
        "date_regex = re.compile(r'\\b\\d{1,2}/\\d{1,2}/\\d{2,4}\\b|\\b\\d{1,2}-\\d{1,2}-\\d{2,4}\\b|\\b\\d{4}-\\d{2}-\\d{2}\\b|\\b\\d{2,4}/\\d{2}/\\d{2,4}\\b')\n",
        "price_regex = re.compile(r'\\b\\d+[\\.,]?\\d*\\s?(€|EUR|euros?|dollars?|USD|CHF)\\b')\n",
        "french_word_regex = re.compile(r'\\b[a-zA-ZàâäéèêëîïôöùûüÿçÀÂÄÉÈÊËÎÏÔÖÙÛÜŸÇ]+\\b')\n",
        "number_regex = re.compile(r'\\b\\d+\\b')\n",
        "\n",
        "# Définir une expression régulière pour les éléments indésirables (ponctuation et autres caractères non désirés)\n",
        "unwanted_regex = re.compile(r'[^\\w\\s€|EUR|euros|dollars|USD|CHFàâäéèêëîïôöùûüÿçÀÂÄÉÈÊËÎÏÔÖÙÛÜŸÇ\\'/-]')\n",
        "\n",
        "# Fonction pour filtrer le texte\n",
        "def filter_text(text):\n",
        "    filtered_elements = []\n",
        "    words = text.split()\n",
        "\n",
        "    for word in words:\n",
        "        # Supprimer les signes de ponctuation et autres caractères non désirés\n",
        "        clean_word = unwanted_regex.sub('', word)\n",
        "\n",
        "        if date_regex.match(clean_word) or price_regex.match(clean_word) or french_word_regex.match(clean_word) or number_regex.match(clean_word):\n",
        "            filtered_elements.append(clean_word)\n",
        "\n",
        "    return ' '.join(filtered_elements)"
      ],
      "metadata": {
        "id": "zW2Hg2sjCs61"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Test pré-traitement\n",
        "# Exemple d'utilisation\n",
        "text = \"Bonjour, je veux acheter une voiture le 12/06/2024 pour 1500 EUR. Mon chat aime bien jouer avec la souris. La date d'aujourd'hui est 2024-06-10. J'ai 2 chats et 1 chien.\"\n",
        "filtered_text = filter_text(text)\n",
        "print(filtered_text)"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7l2jja9MXuS",
        "outputId": "7c9ad232-7482-4401-cd7f-e865008ceac4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bonjour je veux acheter une voiture le 12/06/2024 pour 1500 EUR Mon chat aime bien jouer avec la souris La date d'aujourd'hui est 2024-06-10 J'ai 2 chats et 1 chien\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Appels Azure Vision\n",
        "https://learn.microsoft.com/fr-ca/python/api/overview/azure/ai-vision-imageanalysis-readme?view=azure-python-preview"
      ],
      "metadata": {
        "id": "0BQUwvcHXm8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
        "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "\n",
        "# Set the values of your computer vision endpoint and computer vision key\n",
        "# as environment variables:\n",
        "try:\n",
        "    endpoint = VISION_ENDPOINT\n",
        "    key = VISION_KEY\n",
        "except KeyError:\n",
        "    print(\"Missing environment variable 'VISION_ENDPOINT' or 'VISION_KEY'\")\n",
        "    print(\"Set them before running this sample.\")\n",
        "    exit()\n",
        "\n",
        "# Create an Image Analysis client for synchronous operations\n",
        "client = ImageAnalysisClient(\n",
        "    endpoint=endpoint,\n",
        "    credential=AzureKeyCredential(key)\n",
        ")"
      ],
      "metadata": {
        "id": "mdBVcijLXg7i"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Test AzureVision\n",
        "test=True\n",
        "\n",
        "if test:\n",
        "    # Load image to analyze into a 'bytes' object\n",
        "    with open(\"billet_medecin.png\", \"rb\") as f:\n",
        "        image_data = f.read()\n",
        "\n",
        "    # Extract text (OCR) from an image stream. This will be a synchronously (blocking) call.\n",
        "    result = client.analyze(\n",
        "        image_data=image_data,\n",
        "        visual_features=[VisualFeatures.READ, VisualFeatures.OBJECTS, VisualFeatures.TAGS]\n",
        "    )\n",
        "\n",
        "    # Print text (OCR) analysis results to the console\n",
        "    #print(\"Image analysis results:\")\n",
        "    #print(\" Read:\")\n",
        "    #if result.read is not None:\n",
        "    #  if result.read.blocks != []:\n",
        "    #    for line in result.read.blocks[0].lines:\n",
        "    #        print(f\"   Line: '{line.text}', Bounding box {line.bounding_polygon}\")\n",
        "    #        for word in line.words:\n",
        "    #            print(f\"     Word: '{word.text}', Bounding polygon {word.bounding_polygon}, Confidence {word.confidence:.4f}\")\n",
        "    if result.tags is not None:\n",
        "      print(\" Tags:\")\n",
        "      for o in result.tags.list:\n",
        "          print(f\"   tag: '{o}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cVSkc4-cX5g",
        "outputId": "e4070041-3489-4b7f-e442-50721c0cef9b",
        "cellView": "form"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Tags:\n",
            "   tag: '{'name': 'text', 'confidence': 0.9999969601631165}'\n",
            "   tag: '{'name': 'handwriting', 'confidence': 0.9552189111709595}'\n",
            "   tag: '{'name': 'paper', 'confidence': 0.9217326641082764}'\n",
            "   tag: '{'name': 'ink', 'confidence': 0.8959403038024902}'\n",
            "   tag: '{'name': 'paper product', 'confidence': 0.8882708549499512}'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get text (OCR) analysis results\n",
        "def get_all_words(result):\n",
        "    all_words = []\n",
        "    if result.read.blocks != []:\n",
        "      for line in result.read.blocks[0].lines:\n",
        "          for word in line.words:\n",
        "              all_words.append(word.text)\n",
        "    return all_words\n",
        "\n",
        "def get_all_tags(result):\n",
        "    all_tags = []\n",
        "    if result.tags is not None:\n",
        "      all_tags = result.tags.list\n",
        "    return all_tags\n",
        "\n",
        "if test:\n",
        "  print(get_all_words(result))\n",
        "  print(get_all_tags(result))"
      ],
      "metadata": {
        "id": "EnXYFpLWc7xJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3899438f-9157-4822-cc1d-084f899ba38a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['HYGEA', 'clinique', 'médicale', '5100', 'boul.', 'de', 'Maisonneuve', 'O.', 'Bureau', '710', 'Tél.', ':', '514-938-0995', 'Montréal', '(Qc)', 'H4A', '3T2', 'Fax', ':', '514-938-4476', '.Sul,', '31/23', 'Date', ':', 'Marina', 'Grandin', 'Nom', ':', 'Addresse', ':', 'R', 'Custom', 'orthotics', 'Dx', 'Hallux', 'Valgus', 'Geld', 'sman', '87582']\n",
            "[{'name': 'text', 'confidence': 0.9999969601631165}, {'name': 'handwriting', 'confidence': 0.9552189111709595}, {'name': 'paper', 'confidence': 0.9217326641082764}, {'name': 'ink', 'confidence': 0.8959403038024902}, {'name': 'paper product', 'confidence': 0.8882708549499512}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty dictionary to store the extracted text\n",
        "text_dict = {}\n",
        "tags_dict = {}\n",
        "\n",
        "def document_texts_detection(img_path, debug=False):\n",
        "    # Check if the image has already been seen\n",
        "    if img_path not in text_dict:\n",
        "        # Load image to analyze into a 'bytes' object\n",
        "        with open(img_path, \"rb\") as f:\n",
        "            image_data = f.read()\n",
        "\n",
        "        # Extract text (OCR) from an image stream. This will be a synchronously (blocking) call.\n",
        "        result = client.analyze(\n",
        "            image_data=image_data,\n",
        "            visual_features=[VisualFeatures.READ, VisualFeatures.TAGS]\n",
        "        )\n",
        "        # Store the extracted text in the dictionary\n",
        "        text_dict[img_path] = get_all_words(result)\n",
        "        tags_dict[img_path] = get_all_tags(result)\n",
        "\n",
        "    # Return the extracted text from the dictionary\n",
        "    return text_dict[img_path], tags_dict[img_path]\n"
      ],
      "metadata": {
        "id": "TQyQ0-cUMQTW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Appels OpenAI pour embeddings\n",
        "https://learn.microsoft.com/en-us/azure/ai-services/openai/tutorials/embeddings?tabs=python-new%2Ccommand-line&pivots=programming-language-python\n",
        "\n",
        "* Voir aussi les compétiteurs : https://blog.voyageai.com/2024/06/10/voyage-multilingual-2-multilingual-embedding-model/\n",
        ">* A essayer : https://docs.voyageai.com/docs/api-key-and-installation"
      ],
      "metadata": {
        "id": "nRloA_YvXvS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import openai\n",
        "\n",
        "openai.api_key = openai_api_key\n",
        "\n",
        "client_openai = OpenAI(api_key=openai.api_key)"
      ],
      "metadata": {
        "id": "B0ESjaQLoFuF"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Initialize an empty dictionary to store the embeddings\n",
        "embeddings_dict = {}\n",
        "\n",
        "def get_text_embedding(input, model=\"text-embedding-3-small\"):\n",
        "\n",
        "    if input != None and input != \"\":\n",
        "        # Check if the input has already been seen\n",
        "        if input not in embeddings_dict:\n",
        "            embeddings_batch_response_openAI = client_openai.embeddings.create(input = [input], model=model)\n",
        "            # Store the embedding in the dictionary\n",
        "            embeddings_dict[input] = np.array([embeddings_batch_response_openAI.data[0].embedding])\n",
        "        # Return the embedding from the dictionary\n",
        "        return embeddings_dict[input]\n",
        "    else:\n",
        "        return np.zeros((1, 1536))"
      ],
      "metadata": {
        "id": "cu7S2WEyHcou"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tests des appels"
      ],
      "metadata": {
        "id": "X3QHTo0xius7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = document_texts_detection(img_path=\"recu_masso_photo.png\", debug=False)"
      ],
      "metadata": {
        "id": "c97yS-pGizik"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Nombre de mots/token détectés: {len(texts)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMh0FP2yjjRA",
        "outputId": "c848d584-a3c8-4fab-912c-70b9a67ab03b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre de mots/token détectés: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Texte pour test\n",
        "texte = \"\"\"\n",
        "Université\n",
        "de Montréal\n",
        "Denis Lemarchand\n",
        "4958 avenue grosvenor\n",
        "montreal QC H3W 2M1\n",
        "Canada\n",
        "Programme d'études:\n",
        "Spécialisation:\n",
        "Relevé de notes non officiel\n",
        "Relevé des études de cycles supérieurs\n",
        "Automne 2022\n",
        "217510 Informatique (Maîtrise)\n",
        "Apprentissage automatique (Spécialisation)\n",
        "Date d'émission:\n",
        "Matricule:\n",
        "CPER QC:\n",
        "2024-01-25\n",
        "20241211\n",
        "LEMD02036912\n",
        "Cours\n",
        "IFT 6390\n",
        "Description\n",
        "Crédits:\n",
        "Apprent. machine: fondements\n",
        "Suivis\n",
        "4.000\n",
        "Obtenus\n",
        "4.000\n",
        "Note Points\n",
        "A\n",
        "16.000\n",
        "Moy.gr.\n",
        "2-175-1-0 72 Cours à option\n",
        "Crédits:\n",
        "Suivis\n",
        "Moyenne générale trimestrielle\n",
        "4.000 Total du trimestre\n",
        "4.000\n",
        "Obtenus\n",
        "4.000\n",
        "Moy.\n",
        "4.000\n",
        "Points\n",
        "16.000\n",
        "Hiver 2023\n",
        "Programme d'études:\n",
        "Spécialisation:\n",
        "217510 Informatique (Maîtrise)\n",
        "Apprentissage automatique (Spécialisation)\n",
        "Cours\n",
        "Description\n",
        "Crédits:\n",
        "IFT 6135\n",
        "Aprentissage de représent.\n",
        "Suivis\n",
        "4.000\n",
        "Obtenus\n",
        "4.000\n",
        "Note Points\n",
        "A-\n",
        "14.800\n",
        "Moy.gr.\n",
        "2-175-1-0 72 Cours à option\n",
        "Crédits:\n",
        "Moyenne générale trimestrielle\n",
        "3.700 Total du trimestre\n",
        "Suivis\n",
        "4.000\n",
        "Obtenus\n",
        "4.000\n",
        "Moy.\n",
        "4.000\n",
        "Points\n",
        "14.800\n",
        "Automne 2023\n",
        "Programme d'études:\n",
        "Spécialisation:\n",
        "217510 Informatique (Maîtrise)\n",
        "Apprentissage automatique (Spécialisation)\n",
        "Cours\n",
        "Description\n",
        "Crédits:\n",
        "IFT 6758\n",
        "Science des données\n",
        "Suivis\n",
        "4.000\n",
        "Obtenus\n",
        "4.000\n",
        "Note Points\n",
        "A\n",
        "16.000\n",
        "Moy.gr.\n",
        "2-175-1-0 72 Cours à option\n",
        "Crédits:\n",
        "Suivis\n",
        "Moyenne générale trimestrielle\n",
        "4.000 Total du trimestre\n",
        "4.000\n",
        "Obtenus\n",
        "4.000\n",
        "Moy.\n",
        "4.000\n",
        "Points\n",
        "16.000\n",
        "Hiver 2024\n",
        "Programme d'études:\n",
        "Spécialisation:\n",
        "217510 Informatique (Maîtrise)\n",
        "Intelligence artificielle (Spécialisation)\n",
        "Cours\n",
        "Description\n",
        "Crédits:\n",
        "IFT 6261\n",
        "Traitement des connaissances\n",
        "2-175-1-0 72 Cours à option\n",
        "Suivis\n",
        "Obtenus Note\n",
        "Points\n",
        "Moy.gr.\n",
        "Pour être officiel, le relevé de notes doit porter le sceau de l'Université et la signature du Registraire.\n",
        "Page 1 de 2\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "pvBn5arra0QD",
        "cellView": "form"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tests similarité"
      ],
      "metadata": {
        "id": "FXQzYZOJGj1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texte1 = \"recevoir une paye pour son métier\"\n",
        "texte2 = \"une bulletin de salaire emploi ou travail ou profession ou tâche\"\n",
        "vector1 = get_text_embedding(texte1)\n",
        "vector2 = get_text_embedding(texte2)\n",
        "cosine_similarity(vector1, vector2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfSDYrFPGqXV",
        "outputId": "858ba98c-c923-42a2-cc6b-0b890276078b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.51359817]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texte1 = \"recevoir une peine pour son crime\"\n",
        "texte2 = \"une bulletin de salaire emploi ou travail ou profession ou tâche\"\n",
        "vector1 = get_text_embedding(texte1)\n",
        "vector2 = get_text_embedding(texte2)\n",
        "cosine_similarity(vector1, vector2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vv5SXRHEqQzl",
        "outputId": "acb89830-fd69-423f-bfb6-afe626b6b43d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.21518421]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texte1 = \"recevoir une peine pour un crime\"\n",
        "texte2 = \"application d'une décision de jugement pénal\"\n",
        "vector1 = get_text_embedding(texte1)\n",
        "vector2 = get_text_embedding(texte2)\n",
        "cosine_similarity(vector1, vector2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3lPS2E5qYIQ",
        "outputId": "4801ff72-2af8-433b-933d-af289ba60c2b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5661862]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texte1 = \"recevoir une paye pour son métier\"\n",
        "texte2 = \"application d'une décision de jugement pénal\"\n",
        "vector1 = get_text_embedding(texte1)\n",
        "vector2 = get_text_embedding(texte2)\n",
        "cosine_similarity(vector1, vector2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rti8ZQ8l_USK",
        "outputId": "3bd969aa-d3d7-4786-8f76-c0c16b24615e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.29377192]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_cosine_similarity(vector1, vector2):\n",
        "    #Produit scalaire des vecteurs\n",
        "    scalar_product = np.dot(vector1, vector2.T)\n",
        "    #Norme euclidienne des vecteurs\n",
        "    norm_vector1 = np.linalg.norm(vector1)\n",
        "    norm_vector2 = np.linalg.norm(vector2)\n",
        "    #Expression analytique du cosinus dans un espace euclidien\n",
        "    cosine = scalar_product / (norm_vector1 * norm_vector2)\n",
        "    return cosine\n",
        "\n",
        "my_cosine_similarity(vector1, vector2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeeVZX37Bw0J",
        "outputId": "4ce68556-a471-4316-f6e9-118471b10fba"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.29377192]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#text-embedding-ada-002, text-embedding-3-small, text-embedding-3-large\n",
        "model=\"text-embedding-3-large\"\n",
        "cosine_similarity(get_text_embedding(texte1, model=model), get_text_embedding(texte2, model=model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYncEhYyKNDU",
        "outputId": "a945302e-db45-421d-e4db-61402a7bad93"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.29377192]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Classification"
      ],
      "metadata": {
        "id": "AkTfVi4OC4vW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the mapping of sub-types to types\n",
        "type_mapping = {\n",
        "    \"Relevé de notes officiel universitaire\": \"Bulletin de notes\",\n",
        "    \"Relevé de notes non officiel universitaire\": \"Bulletin de notes\",\n",
        "    \"Bulletin cumulatif de notes\": \"Bulletin de notes\",\n",
        "    \"Cours avec moyenne générale trimestrielle\": \"Bulletin de notes\",\n",
        "    \"Crédits obtenus et notes\": \"Bulletin de notes\",\n",
        "\n",
        "    \"Facture session universitaire\": \"Preuve de scolarité\",\n",
        "    \"Horaire de cours\": \"Preuve de scolarité\",\n",
        "    \"Confirmation d'inscription\": \"Preuve de scolarité\",\n",
        "    \"Statut étudiant temps plein ou temps partiel\": \"Preuve de scolarité\",\n",
        "    \"Attestation d'études\": \"Preuve de scolarité\",\n",
        "\n",
        "    \"Certificat médical\": \"Billet du médecin\",\n",
        "    \"Formulaire d'arrêt de travail\": \"Billet du médecin\",\n",
        "    \"Billet du medecin\": \"Billet du médecin\",\n",
        "    \"Prescription médicale\": \"Billet du médecin\",\n",
        "    \"Ordonnance médicale clinique\": \"Billet du médecin\",\n",
        "\n",
        "    \"Spécimen de chèque\": \"Spécimen de chèque\",\n",
        "    \"Payer à l'ordre de\": \"Spécimen de chèque\",\n",
        "    \"100 dollars\": \"Spécimen de chèque\",\n",
        "    \"Banque\": \"Spécimen de chèque\",\n",
        "    \"MICR code\": \"Spécimen de chèque\"#,\n",
        "\n",
        "    #\"Facture soins dentaires\": \"Facture\",\n",
        "    #\"Facture soin thérapeutique\": \"Facture\",\n",
        "    #\"Facture ou reçu soin massage thérapeutique\": \"Facture\",\n",
        "    #\"Facture et services\": \"Facture\"\n",
        "}\n",
        "\n",
        "# Derive types_doc from type_mapping\n",
        "sous_types_doc = list(type_mapping.keys())\n",
        "sous_types_doc_original = sous_types_doc.copy()\n",
        "type_mapping_original = type_mapping.copy()"
      ],
      "metadata": {
        "id": "x31_1u0HJlUZ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def classify_text(texte, sous_types_doc, seuil=0.4):\n",
        "    classification = {}\n",
        "    insert_autre = False\n",
        "    total_score = 0\n",
        "\n",
        "    # Calcul de la similarité pour chaque type de document\n",
        "    for sous_type in sous_types_doc:\n",
        "        similarity_score = cosine_similarity(get_text_embedding(texte), get_text_embedding(sous_type))[0][0]\n",
        "        if similarity_score >= seuil:\n",
        "            doc_type = type_mapping[sous_type]\n",
        "            if doc_type in classification:\n",
        "                classification[doc_type][\"cumul des scores de similarité\"] += similarity_score\n",
        "            else:\n",
        "                classification[doc_type] = {\"cumul des scores de similarité\": similarity_score}\n",
        "            total_score += similarity_score\n",
        "        elif not insert_autre:\n",
        "            if \"Autre\" in classification:\n",
        "                classification[\"Autre\"][\"cumul des scores de similarité\"] += seuil\n",
        "            else:\n",
        "                classification[\"Autre\"] = {\"cumul des scores de similarité\": seuil}\n",
        "            total_score += seuil\n",
        "            insert_autre = True\n",
        "\n",
        "    # Calcul du pourcentage de chaque score de similarité\n",
        "    for doc_type, item in classification.items():\n",
        "        item[\"part dans la classification (%)\"] = round((item[\"cumul des scores de similarité\"] / total_score) * 100, 2)\n",
        "\n",
        "    # Tri des résultats par score de similarité en ordre décroissant\n",
        "    sorted_classification = sorted(classification.items(), key=lambda x: x[1][\"cumul des scores de similarité\"], reverse=True)\n",
        "\n",
        "    # Conversion de la liste triée en format JSON\n",
        "    return json.dumps(sorted_classification, indent=4), sorted_classification[0][1]['part dans la classification (%)']"
      ],
      "metadata": {
        "id": "Yfm4kyoxJ2Vt"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Test classification\n",
        "img_path = convert_pdf_to_jpg(\"releve_notes.pdf\") #\"McGill_Enrolment_Letter_2023-2024.pdf\"\n",
        "img_path = convert_docx_to_pdf(img_path)\n",
        "texte, _ = document_texts_detection(img_path=img_path)\n",
        "texte = \" \".join(texte)\n",
        "classification_sorted, best = classify_text(filter_text(texte), sous_types_doc, seuil=0.4963)\n",
        "json.loads(classification_sorted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ9Fj4i4rQj4",
        "outputId": "ba4f315f-d183-4231-b1a4-f40018369639"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Bulletin de notes',\n",
              "  {'cumul des scores de similarité': 1.6570217881306248,\n",
              "   'part dans la classification (%)': 62.49}],\n",
              " ['Preuve de scolarité',\n",
              "  {'cumul des scores de similarité': 0.4982181809853169,\n",
              "   'part dans la classification (%)': 18.79}],\n",
              " ['Autre',\n",
              "  {'cumul des scores de similarité': 0.4963,\n",
              "   'part dans la classification (%)': 18.72}]]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def objective_function(seuil, filtered_text, sous_types_doc):\n",
        "    _, best = classify_text(filtered_text, sous_types_doc, seuil)\n",
        "    return best\n",
        "\n",
        "def find_best_seuil(texte, sous_types_doc, seuil_max=0.45, tol=1e-3):\n",
        "    filtered_text = filter_text(texte)\n",
        "\n",
        "    low = 0.0\n",
        "    high = seuil_max\n",
        "\n",
        "    best_seuil = (low + high) / 2.0\n",
        "    best_value = objective_function(best_seuil, filtered_text, sous_types_doc)\n",
        "\n",
        "    while (high - low) > tol:\n",
        "        mid1 = low + (high - low) / 3\n",
        "        mid2 = high - (high - low) / 3\n",
        "\n",
        "        value1 = objective_function(mid1, filtered_text, sous_types_doc)\n",
        "        value2 = objective_function(mid2, filtered_text, sous_types_doc)\n",
        "\n",
        "        if value1 > value2:\n",
        "            high = mid2\n",
        "        else:\n",
        "            low = mid1\n",
        "\n",
        "        best_seuil = (low + high) / 2.0\n",
        "        best_value = objective_function(best_seuil, filtered_text, sous_types_doc)\n",
        "\n",
        "    return best_seuil, best_value\n",
        "\n",
        "best_seuil, best_value = find_best_seuil(texte, sous_types_doc, seuil_max=0.6)\n",
        "print(f\"Le meilleur seuil est {best_seuil} avec une valeur de {best_value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inve7R-TYgTt",
        "outputId": "843c3137-5969-4b2e-ef97-1cd19e59f4aa"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le meilleur seuil est 0.4986384677244059 avec une valeur de 76.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Interface UI pour les tests PO-AA"
      ],
      "metadata": {
        "id": "stynIthZjKca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_document(img_path, new_type_doc, categorie, parametres, seuil):\n",
        "    global sous_types_doc_original, type_mapping_original, sous_types_doc, type_mapping\n",
        "\n",
        "    img_path = convert_pdf_to_jpg(img_path)\n",
        "    img_path = convert_docx_to_pdf(img_path)\n",
        "    texts, tags = document_texts_detection(img_path=img_path)\n",
        "    texts = \" \".join(texts)\n",
        "    image = get_PIL_image(img_path=img_path)\n",
        "\n",
        "    if \"Réinitialiser la liste des sous-types/types\" in parametres:\n",
        "        types_doc_etendu = sous_types_doc_original.copy()\n",
        "        sous_types_doc = sous_types_doc_original.copy()\n",
        "        type_mapping = type_mapping_original.copy()\n",
        "    else:\n",
        "        types_doc_etendu = sous_types_doc.copy()\n",
        "        if new_type_doc != \"\":\n",
        "            if new_type_doc not in sous_types_doc:\n",
        "                types_doc_etendu.append(new_type_doc)\n",
        "                # Add the new type to the type_mapping dictionary\n",
        "                type_mapping[new_type_doc] = categorie\n",
        "\n",
        "    if \"Nettoyage Texte\" in parametres:\n",
        "        texts = filter_text(texts)\n",
        "\n",
        "    if \"Calcul meilleur seuil\" in parametres:\n",
        "        best_seuil, best = find_best_seuil(texts, types_doc_etendu, seuil_max=float(seuil), tol=1e-3)\n",
        "        seuil = best_seuil\n",
        "\n",
        "    analyse, best = classify_text(texts, types_doc_etendu, seuil=seuil)\n",
        "\n",
        "    return image, seuil, analyse, texts, tags, type_mapping"
      ],
      "metadata": {
        "id": "Z8JJU2p7KTTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# URL de l'image du diagramme\n",
        "#diagram_url = \"https://diagrams.helpful.dev/d/d:P8TaRIVr-png-base-64-for-mobile\"\n",
        "diagram_url = \"https://mermaid.ink/img/pako:eNp9U0FOwzAQ_MrKF0CiPCCHSqj0gIRUiSJOuSz2ElZK7GBvKgriQX1HP8Y6TUtpgFxie2cmuzPxh7HBkSlMoteOvKUbxipiU3rQp8UobLlFL3ATbNeQLjDB7AVjRf3OdeCGyphz22BFPSH4FcXEwQN54Hw8Ri9m9xk7f5OIVjJWxYXehOD8-r2LBI-cJS7G1HnzRM6xr3qB1KIlWJGVKzhftOSvb78Rv7BnIbGnJTdcY2RZ7zpuFIKctA1dQNpXt5u_vXlYt5Qy-46Tdu3OthsfvN1uEjgC0Wp-7_1KY6F7Sl0tRxISebuhcQc76v67k-m0t7oYkolQ00ksfV1xanIxxCEcT9LQokIOVhW7LFid38VAAqXJvobIiWJpfrbRj_9ToDSPR3A49iNlQ0IdKqbBiQNPNU4zKYZEdLZshg1pMorklDNRncHRApahH7hGqP911lyahmKD7PRWfGTh0siL_uylyeM4ekYVzKN_KhQ7Ccu1t6aQ2NGl6VqHsr9EpnjGOh1O547VieHw8wur_0EX?type=png\"\n",
        "cosin_similarity_graph = \"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dyH20eCqb6qTL-gt4nCVzQ.png\"\n",
        "\n",
        "# Interface Gradio\n",
        "demo = gr.Blocks()\n",
        "\n",
        "with demo:\n",
        "    gr.Markdown(\"# Démo IDP - OCR (ici Azure Vision) - Classification par similarité\")\n",
        "    gr.Image(value=diagram_url, label=\"\")\n",
        "\n",
        "    threshold_slider = gr.Slider(0.0, 1, value=0.5, label=\"Seuil similarité\")\n",
        "\n",
        "    outputs=[gr.Image(label=\"Image du doc\", type=\"pil\"), #gr.Textbox(label=\"Langue détectée\"),\n",
        "            gr.Textbox(label=\"Meilleur seuil\"),\n",
        "            gr.Json(label=\"Classification par similarité (0-Shot classification)\"),\n",
        "            gr.Textbox(label=\"Tous les mots extraits (et filtrés)\"),\n",
        "            gr.Json(label=\"Tags extraits\"),\n",
        "            gr.Json(label=\"Regroupement des sous-types par types (actuellement en mémoire)\")]\n",
        "\n",
        "    gr.Interface(\n",
        "            fn=process_document,\n",
        "            inputs=[gr.File(label=\"Fichier\", type=\"filepath\", file_types=[\".jpg\",\".pdf\",\".png\",\".docx\"]),\n",
        "                    gr.Textbox(label=\"Ajouter un sous-type de document\"),\n",
        "                    gr.Dropdown(\n",
        "                        [\"Preuve de scolarité\", \"Bulletin de notes\",\"Billet du médecin\", \"Spécimen de chèque\"], label=\"Dans la catégorie\", value=\"Preuve de scolarité\"),\n",
        "                    gr.CheckboxGroup([\"Nettoyage du texte\", \"Réinitialiser la liste des sous-types/types\", \"Calcul meilleur seuil\"], label=\"Paramètres\"),\n",
        "                    threshold_slider],\n",
        "            outputs=outputs,\n",
        "            title=None,\n",
        "            examples= [[\"fac_ortho.jpg\"],[\"billet_medecin.png\"],[\"recu_masso_photo.png\"],[\"McGill_Enrolment_Letter_2023-2024.pdf\"],[\"releve_notes.pdf\"]],\n",
        "            cache_examples=False, allow_flagging='never', clear_btn=None)\n",
        "\n",
        "    gr.Image(value=cosin_similarity_graph, label=\"\")"
      ],
      "metadata": {
        "id": "s54GdWR3jQcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "kJpgmOyiksgo",
        "outputId": "65fe0bb5-68e0-4a26-ce2e-ca6586a4ba91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://50c15e7b4c09811fd0.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://50c15e7b4c09811fd0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://50c15e7b4c09811fd0.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Interface UI pour client"
      ],
      "metadata": {
        "id": "nOYTMK9hw5Pn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_document(img_path, seuil_max=0.49):\n",
        "    global sous_types_doc_original, type_mapping_original, sous_types_doc, type_mapping\n",
        "\n",
        "    img_path = convert_pdf_to_jpg(img_path)\n",
        "    img_path = convert_docx_to_pdf(img_path)\n",
        "    texts, tags = document_texts_detection(img_path=img_path)\n",
        "    texts = \" \".join(texts)\n",
        "    image = get_PIL_image(img_path=img_path)\n",
        "\n",
        "    texts = filter_text(texts)\n",
        "\n",
        "    types_doc_etendu = sous_types_doc_original.copy()\n",
        "    seuil, best = find_best_seuil(texts, types_doc_etendu, seuil_max=seuil_max, tol=1e-3)\n",
        "\n",
        "    analyse, best = classify_text(texts, types_doc_etendu, seuil=seuil)\n",
        "\n",
        "    return json.loads(analyse)[0][0], image"
      ],
      "metadata": {
        "id": "fMOg9m87xW9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Interface Gradio\n",
        "poc = gr.Blocks()\n",
        "\n",
        "with poc:\n",
        "    gr.Markdown(\"# PoC IDP - Classification de documents par similarité\")\n",
        "\n",
        "    outputs=[\n",
        "            gr.Text(label=\"Classification par similarité (0-Shot classification)\"),\n",
        "            gr.Image(label=\"Image du doc\", type=\"pil\")\n",
        "            ]\n",
        "\n",
        "    gr.Interface(\n",
        "            fn=process_document,\n",
        "            inputs=[gr.File(label=\"Fichier\", type=\"filepath\", file_types=[\".jpg\",\".pdf\",\".png\",\".docx\"]),\n",
        "                    ],\n",
        "            outputs=outputs,\n",
        "            title=None,\n",
        "            examples= [[\"billet_medecin.png\"],[\"McGill_Enrolment_Letter_2023-2024.pdf\"],[\"releve_notes.pdf\"]],\n",
        "            cache_examples=False, allow_flagging='never', clear_btn=None, submit_btn=\"Classifier\")\n"
      ],
      "metadata": {
        "id": "M0LennZixa1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poc.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "ZeFDLAaFxkOG",
        "outputId": "24790f07-ab5d-4437-dfa4-651324d2a3b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://3f40116f2a722632dc.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3f40116f2a722632dc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://3f40116f2a722632dc.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##interface UI pour traitement en lot"
      ],
      "metadata": {
        "id": "9qF_hxAJRNEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_class(img_path, seuil_max=0.49):\n",
        "    global sous_types_doc_original, type_mapping_original, sous_types_doc, type_mapping\n",
        "\n",
        "    img_path = convert_pdf_to_jpg(img_path)\n",
        "    img_path = convert_docx_to_pdf(img_path)\n",
        "    texts, tags = document_texts_detection(img_path=img_path)\n",
        "    texts = \" \".join(texts)\n",
        "    image = get_PIL_image(img_path=img_path)\n",
        "\n",
        "    texts = filter_text(texts)\n",
        "\n",
        "    types_doc_etendu = sous_types_doc_original.copy()\n",
        "    seuil, best = find_best_seuil(texts, types_doc_etendu, seuil_max=seuil_max, tol=1e-3)\n",
        "\n",
        "    analyse, best = classify_text(texts, types_doc_etendu, seuil=seuil)\n",
        "\n",
        "    return json.loads(analyse)[0][0], seuil"
      ],
      "metadata": {
        "id": "fWLD_jLI5UA2"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def unzip_and_get_df(zip_file, batch_path=\"temp_extracted_files\", target_file=\"0-shot-classif.xlsx\"):\n",
        "    # Create a temporary directory to extract files\n",
        "    os.makedirs(batch_path, exist_ok=True)\n",
        "\n",
        "    # Extract the zip file\n",
        "    with zipfile.ZipFile(zip_file.name, 'r') as zip_ref:\n",
        "        zip_ref.extractall(batch_path)\n",
        "\n",
        "    # Locate the specific Excel file\n",
        "    file_path = os.path.join(batch_path, target_file)\n",
        "\n",
        "    # Check if the target file exists\n",
        "    if os.path.exists(file_path):\n",
        "        # Load the Excel file into a DataFrame\n",
        "        df = pd.read_excel(file_path)\n",
        "        return df\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"File {target_file} not found in the zip archive.\")\n",
        "\n",
        "def highlight(s):\n",
        "    if s.target != s.predict:\n",
        "        if (s.target == \"Bulletin de notes\" and s.predict == \"Preuve de scolarité\") or (s.target == \"Preuve de scolarité\" and s.predict == \"Bulletin de notes\"):\n",
        "          return ['color:black;background-color:gray'] * len(s)\n",
        "        else:\n",
        "          return ['color:white;background-color:purple'] * len(s)\n",
        "    else:\n",
        "        return ['color:black;background-color:white'] * len(s)\n",
        "\n",
        "def process_data(zip_file, seuil_max, batch_path=\"temp_extracted_files\", target_file=\"0-shot-classif.xlsx\"):\n",
        "    # Get the dataframe from the unzip_and_get_df function\n",
        "    df = unzip_and_get_df(zip_file, batch_path, target_file)\n",
        "\n",
        "    # Combine 'file_name' and 'file_ext' columns to create the list of files\n",
        "    df['doc_name'] = df['file_name'].astype(str) + '.' + df['file_ext'].astype(str)\n",
        "\n",
        "    # Process each file with process_document and update the dataframe\n",
        "    predicted_classes = []\n",
        "    best_seuils = []\n",
        "    for file_name in df['doc_name']:\n",
        "        file_path = os.path.join(batch_path, file_name)\n",
        "        try:\n",
        "          predicted_class, best_seuil = predict_class(file_path, seuil_max=seuil_max)\n",
        "          predicted_classes.append(predicted_class)\n",
        "          best_seuils.append(round(best_seuil,3))\n",
        "        except Exception as e:\n",
        "          print(f\"Error processing file {file_name}: {e}\")\n",
        "          predicted_classes.append(\"Erreur\")\n",
        "\n",
        "    df['predicted_class'] = predicted_classes\n",
        "    df['seuil'] = best_seuils\n",
        "    df['seuil'] = df['seuil'].map('{:,.2f}'.format)\n",
        "    df['is_correct_class'] = (df['predicted_class'] == df['target_class']).astype(int)\n",
        "\n",
        "    # Select only the required columns\n",
        "    df_result = df[['doc_name', 'target_class', 'predicted_class', 'seuil']]\n",
        "    df_result.columns = ['doc_name', 'target', 'predict', 'seuil']\n",
        "\n",
        "    # Calculate classification accuracy\n",
        "    overall_accuracy = df['is_correct_class'].mean() * 100\n",
        "    class_accuracy = df.groupby('target_class')['is_correct_class'].mean() * 100\n",
        "\n",
        "    textstr = f'Taux de bonne classification au global : {overall_accuracy:.2f}%\\n'\n",
        "    for cls, acc in class_accuracy.items():\n",
        "        textstr += f'         - Taux pour {cls}: {acc:.2f}%\\n'\n",
        "\n",
        "    return df_result.style.apply(highlight, axis=1), textstr\n",
        "\n",
        "poc = gr.Blocks()\n",
        "\n",
        "with poc:\n",
        "    gr.Markdown(\"# PoC IDP - Classification de documents par similarité - traitement en lot\")\n",
        "\n",
        "    input_zip = gr.File(label=\"Fichier ZIP contenant les échantillons à classer\")\n",
        "    threshold_slider = gr.Slider(0.0, 1, value=0.31, label=\"Seuil similarité max\")\n",
        "    submit_btn = gr.Button(\"Classifier\")\n",
        "\n",
        "    output_df = gr.Dataframe(label=\"\")\n",
        "    output_text = gr.Text(label=\"\")\n",
        "\n",
        "    submit_btn.click(\n",
        "        fn=process_data,\n",
        "        inputs=[input_zip, threshold_slider],\n",
        "        outputs=[output_df, output_text]\n",
        "    )\n"
      ],
      "metadata": {
        "id": "g490F9csRU8s"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poc.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "yhuqbekmnWva",
        "outputId": "097f03b0-a5ef-4ef0-d12e-7de001d1b4bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://09e251b1f29c3f8d6e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://09e251b1f29c3f8d6e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf temp_extracted_files"
      ],
      "metadata": {
        "id": "_0X8lEnEVuiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r 0-shot-classif.zip temp_extracted_files"
      ],
      "metadata": {
        "id": "8CEW9jHxGM8I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}